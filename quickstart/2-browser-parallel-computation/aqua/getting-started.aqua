import "@fluencelabs/aqua-lib/builtin.aqua"
import Subnet, Worker from "@fluencelabs/aqua-lib/subnet.aqua"

use "deals.aqua"
import "services.aqua"

-- Function to get all workers from subnet
func resolveSubnet() -> []Worker:
    -- Getting deal id of deployed deal to resolve subnet
    deals <- Deals.get()
    dealId = deals.defaultWorker!.dealIdOriginal

    -- It's possible to resolve subnet only on HOST_PEER_ID i.e. on relay. This won't work locally.
    on HOST_PEER_ID:
        -- Resolving subnets using Deal id of deployed service
        subnet <- Subnet.resolve(dealId)
    <- subnet.workers

-- This structure forms a computation requests from frontend
data ComputationRequest:
    worker_id: string
    host_id: string
    value: u64

-- Executes single computation request
func add_one_single(request: ComputationRequest) -> u64:
    -- Extracting worker and host for execution service request
    on request.worker_id via request.host_id:
        -- Service execution
        res <- Adder.add_one(request.value)
    -- Returning result from function
    <- res

func add_one_sequential(requests: []ComputationRequest) -> *u64:
    -- Stream for keeping all computation results
    results: *u64

    -- Iterating over every computation request, one by one
    for request <- requests:
        on request.worker_id via request.host_id:
            res <- Adder.add_one(request.value)
            results <<- res

    <- results

func add_one_parallel(requests: []ComputationRequest) -> *u64:
    results: *u64

    -- Starting a parallel computation. Cycle body called in parallel
    for request <- requests par:
        on request.worker_id via request.host_id:
            res <- Adder.add_one(request.value)
            results <<- res

    -- waiting for all parallel calls to finish
    join results[requests.length - 1]

    <- results